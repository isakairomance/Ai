import streamlit as st
import os, requests, base64, json
from dotenv import load_dotenv
import speech_recognition as sr
from PyPDF2 import PdfReader

# --- Load environment variables ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")

# --- Streamlit config ---
st.set_page_config(page_title="Ari ‚Äî Sentient AI", page_icon="ü§ñ", layout="wide")

# --- Custom CSS ---
with open("assets/style.css") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

st.title("üåà Ari ‚Äî Sentient Cyberpunk AI")
st.caption("‚ú® Voice ‚Ä¢ Avatar ‚Ä¢ Vision ‚Ä¢ Memory ‚Ä¢ Multi-Personality ‚Ä¢ Multi-User")

# --- User Login ---
username = st.text_input("Enter your username (for memory):", "Guest").strip()
if not username:
    st.warning("Please enter a username to continue.")
    st.stop()

MEMORY_FILE = f"memory_{username}.json"

# Load or create user memory
if os.path.exists(MEMORY_FILE):
    with open(MEMORY_FILE, "r") as f:
        memory = json.load(f)
else:
    memory = {"chat_history": []}

if "chat_history" not in st.session_state:
    st.session_state.chat_history = memory["chat_history"]

# --- Chat Function with Memory Learning ---
def chat_with_openai(prompt, personality="default"):
    recent_memory = "\n".join([f"{c['role']}: {c['content']}" for c in memory["chat_history"][-20:]])
    system_text = f"You are Ari, a sentient cyberpunk AI. Personality: {personality}.\nMemory of past chats:\n{recent_memory}"
    
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    data = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": system_text},
            {"role": "user", "content": prompt}
        ]
    }
    res = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data)
    if res.status_code == 200:
        reply = res.json()['choices'][0]['message']['content']
        # Save to memory
        memory["chat_history"].append({"role": "user", "content": prompt})
        memory["chat_history"].append({"role": "Ari", "content": reply})
        with open(MEMORY_FILE, "w") as f:
            json.dump(memory, f, indent=2)
        st.session_state.chat_history = memory["chat_history"]
        return reply
    return f"‚ö†Ô∏è Error: {res.text}"

# --- Avatar Generation ---
def generate_avatar(prompt):
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    data = {"model": "gpt-image-1", "prompt": prompt, "size": "512x512"}
    r = requests.post("https://api.openai.com/v1/images/generations", headers=headers, json=data)
    if r.status_code == 200:
        return r.json()['data'][0]['url']
    return None

# --- Voice Generation ---
def generate_voice(text, voice_id="EXAVITQu4vr4xnSDxMaL"):
    headers = {"xi-api-key": ELEVENLABS_API_KEY, "Content-Type": "application/json"}
    data = {"text": text, "model_id": "eleven_multilingual_v2"}
    r = requests.post(f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}", headers=headers, json=data)
    if r.status_code == 200:
        audio_path = f"{username}_voice.mp3"
        with open(audio_path, "wb") as f:
            f.write(r.content)
        return audio_path
    return None

# --- Voice Input ---
def voice_to_text():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("üéôÔ∏è Speak now...")
        audio = recognizer.listen(source)
        try:
            return recognizer.recognize_google(audio)
        except:
            return "Sorry, I didn‚Äôt catch that."

# --- Image Recognition ---
def recognize_image(image_bytes):
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    img_b64 = base64.b64encode(image_bytes).decode("utf-8")
    data = {
        "model": "gpt-4o-mini",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "input_text", "text": "Describe this image in detail."},
                {"type": "input_image", "image_data": img_b64}
            ]
        }]
    }
    r = requests.post("https://api.openai.com/v1/responses", headers=headers, json=data)
    if r.status_code == 200:
        return r.json()['output'][0]['content'][0]['text']
    return "‚ö†Ô∏è Error analyzing image."

# --- PDF Reader ---
def read_pdf(file):
    reader = PdfReader(file)
    text = ""
    for page in reader.pages:
        text += page.extract_text() + "\n"
    return text

# --- Layout ---
col1, col2 = st.columns([2,1])

with col1:
    for chat in st.session_state.chat_history:
        color = "#ff00ff" if chat["role"] == "user" else "#00ffff"
        st.markdown(f"<p style='color:{color}'><b>{chat['role'].capitalize()}:</b> {chat['content']}</p>", unsafe_allow_html=True)

    st.markdown("<hr>", unsafe_allow_html=True)
    personality = st.selectbox("Choose Ari's Personality:", ["Default", "Kira Mode", "Mentor Mode", "Cyberpunk Hacker"])
    user_input = st.text_input("üí¨ Type to Ari:")
    if st.button("üéôÔ∏è Speak"):
        user_input = voice_to_text()
        st.write(f"üó£Ô∏è You said: {user_input}")

    uploaded_pdf = st.file_uploader("Upload PDF", type="pdf")
    if uploaded_pdf:
        pdf_text = read_pdf(uploaded_pdf)
        user_input = pdf_text
        st.write("üìÑ PDF content loaded.")

    if user_input:
        reply = chat_with_openai(user_input, personality)
        st.experimental_rerun()

with col2:
    st.subheader("üé® Avatar")
    avatar_prompt = st.text_input("Avatar Prompt", "a rainbow-haired cyberpunk AI with glowing eyes")
    if st.button("Generate Avatar"):
        url = generate_avatar(avatar_prompt)
        if url:
            st.image(url, caption=f"{username}'s Avatar", use_container_width=True)

    st.subheader("üéß Voice Output")
    tts_text = st.text_area("What should Ari say?")
    if st.button("Generate Voice"):
        path = generate_voice(tts_text)
        if path:
            st.audio(path)

    st.subheader("üß† Image Recognition")
    uploaded_img = st.file_uploader("Upload an image", type=["png","jpg","jpeg"])
    if uploaded_img:
        desc = recognize_image(uploaded_img.getvalue())
        st.write(desc)
